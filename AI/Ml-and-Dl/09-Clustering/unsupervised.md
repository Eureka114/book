# 9.1 无监督学习和聚类

## 无监督学习

无监督学习也称为无监督机器学习，它使用机器学习算法来分析未标记的数据集并进行**聚类**。这些算法无需人工干预，即可发现隐藏的模式或数据分组。

### 无监督学习的应用

机器学习技术已成为改善产品用户体验和测试系统以保证质量的常用方法。 与手动观察相比，无监督学习提供了查看数据的探索性路径，使企业能够更快地识别大量数据中的模式。 在现实世界中，无监督学习的一些最常见应用如下：

- **新闻栏目：**Google 新闻使用无监督学习，对各种在线新闻媒体关于同一故事的文章进行分类。 例如，可以将总统选举的结果归类到“美国”新闻的标签下。
- **计算机视觉：**无监督学习算法用于视觉感知任务，例如物体识别。  
- **医学成像：**无监督机器学习为医学成像设备提供基本功能，例如图像检测、分类和分割，用于放射学和病理学，可以快速准确地诊断患者病情。
- **异常检测：**无监督学习模型可以梳理大量数据，发现数据集中的非典型数据点。 这些异常现象可以提高人们对故障设备、人为错误或安全违规的认知。
- **客户角色：**通过定义客户角色，可以更轻松地了解共同特征和商业客户的购买习惯。 无监督学习使企业能够建立更完善的买家角色档案，让组织能够更恰当地调整自己的产品讯息传达方式。
- **推荐引擎：**无监督学习可使用过去的购买行为数据，帮助发现相关数据趋势，根据这些趋势可制定出更有效的交叉销售策略。 这用于在线上零售商的结账流程中向客户提供相关的附加建议。

### 无监督、 有监督与半监督学习的对比

人们经常会将无监督学习和有监督学习一起讨论。 与无监督学习算法不同的是，有监督学习算法使用标记数据。 有监督学习可以通过这些数据来预测未来的结果，或是根据试图解决的回归或分类问题，将数据分配到特定类别。 虽然有监督学习算法往往比无监督学习模型更准确，但有监督学习事先需要人工干预才能恰当地标记数据。 而这些标记数据集能够让有监督学习算法避免计算复杂性，因为不需要大型训练集就能产生预期结果。 常见的回归和分类技术包括线性和逻辑回归、朴素贝叶斯、KNN 算法和随机森林。

如果给定输入数据中只有一部分被标记，就会进行半监督学习。 无监督学习和半监督学习可能是更具吸引力的替代方案，因为依赖领域专业知识为有监督学习恰当标记数据可能既耗时又成本高昂。

可以参见[Supervised vs. unsupervised learning: What's the difference? | IBM](https://www.ibm.com/think/topics/supervised-vs-unsupervised-learning)。

### 无监督学习面临的难题

虽然无监督学习有很多好处，但在允许机器学习模型无任何人为干预的情况下执行时，可能会遇到一些难题。 其中的一些难题包括：

- 大量训练数据导致的计算复杂性
- 训练时间更长
- 结果不准确的风险较高
- 需要人工干预来验证输出变量
- 数据聚类的基础缺乏透明度

## 聚类

- 聚类是一种经典的**无监督学习**方法，**无监督学习的目标是通过对无标记训练样本的学习，发掘和揭示数据集本身潜在的结构与规律**，即不依赖于训练数据集的类标记信息。聚类则是试图将数据集的样本划分为若干个互不相交的类簇，从而每个簇对应一个潜在的类别。
- 形式化的说，假定样本集$D=\{x_1,x_2,\ldots,x_n\}$包含m个无标记样本， 每个样本都是一个n维特征向量，则聚类算法会将样本集$D$划分为$k$个不相交的簇$\{C_l\mid l\in[1,k]\}$。我们用$\lambda_j\in\{1,2,\ldots,k\}$来表示样本的簇标记(Cluster Label)，即$x_j\in C_l$。于是，聚类的结果可用包含m 个元素的簇标记向量$\mathbf{\lambda}=(\lambda_1;\lambda_2,\ldots,\lambda_n)$。

- 聚类直观上来说是将相似的样本聚在一起，从而形成一个**类簇(Cluster)**。那首先的问题是如何来**度量相似性**(Similarity Measure)呢？这便是**距离度量**，在生活中我们说差别小则相似，对应到多维样本，每个样本可以对应于高维空间中的一个数据点，若它们的距离相近，我们便可以称它们相似。那接着如何来评价聚类结果的好坏呢？这便是**性能度量**，性能度量为评价聚类结果的好坏提供了一系列有效性指标。