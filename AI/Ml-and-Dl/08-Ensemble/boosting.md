# 8.2 Boosting

## 什么是Boosting？

Boosting是一种**串行**的工作机制，即个体学习器的训练存在依赖关系，必须一步一步序列化进行。其基本思想是：增加前一个基学习器在训练训练过程中预测错误样本的权重，使得后续基学习器更加关注这些打标错误的训练样本，尽可能纠正这些错误，一直向下串行直至产生需要的T个基学习器，Boosting最终对这T个学习器进行加权结合，产生学习器委员会。

## AdaBoost: Boosting族的著名算法

- AdaBoosting算法的推导：其有多种推导方式，比较容易理解的是基于“加法模型”，即基学习器的线性组合来最小化指数损失函数。

	
	$$
	\begin{aligned}
		H(x)&=\sum_{t=1}^T\alpha_th_t(x)\\
		\text{Loss}_{exp}(h)&=\mathbb{E}_{x\sim D,y}\left[e^{-yh(x)}\right]
	\end{aligned}
	$$
	

	其中，对于指数部分，若打标正确，则为负；反之，则为正。

- 具体来说，整个Adaboost迭代算法分为3步：

	1. 初始化训练数据的权值分布。如果有N个样本，则每一个训练样本最开始时都被赋予相同的权值：1/N。

	1. 训练弱分类器。具体训练过程中，如果某个样本点已经被准确地分类，那么在构造下一个训练集中，它的权值就被降低；相反，如果某个样本点没有被准确地分类，那么它的权值就得到提高。然后，权值更新过的样本集被用于训练下一个分类器，整个训练过程如此迭代地进行下去。

	1. 将各个训练得到的弱分类器组合成强分类器。各个弱分类器的训练过程结束后，加大分类误差率小的弱分类器的权重，使其在最终的分类函数中起着较大的决定作用，而降低分类误差率大的弱分类器的权重，使其在最终的分类函数中起着较小的决定作用。


	---

- 流程图如下所示：
	![6.png](https://i.loli.net/2018/10/18/5bc84d0d7c057.png)

