# 2.3 性能度量

1. 对学习器的泛化性能进行评估，不仅需要有效可行的实验估计方法，还需要有衡量模型泛化能力的评价标准，这就是**性能度量**(Performance Measure)。

2. 在预测任务中, 给定样例集$D=\left\{\left({x}_{1}, y_{1}\right),\left({x}_{2}, y_{2}\right), \ldots,\left({x}_{m}, y_{m}\right)\right\}$, 其中$y_{i}$ 是示例${x}_{i}$的真实标记。要评估学习器 $f$ 的性能, 就要把学习器预测结果与真实标记$y$进行比较。

## 均方误差(Mean Squared Error)

回归任务最常用的性能度量。

$$
   E(f;D)=\frac{1}{m} \sum_{i=1}^{m}\left(f\left({x}_{i}\right)-y_{i}\right)^{2}
$$

更一般地，对于数据分布${D}$和概率密度函数$p(\cdot)$，均方误差可描述为

$$
   E(f;{D})=\int_{x\sim D}(f({x})-y)^{2} p({x}) \mathrm{d} {x} .
$$

## 错误率和精度

错误率是分类错误的样本数占样本总数的比例，精度则是分类正确的样本数占样本总数的比例。对于样本集D，分类错误率$E(f;D)$为

$$
   E(f;D)=\frac{1}{m} \sum_{i=1}^{m}\mathbb{I} \left(f\left({x}_{i}\right)\neq y_{i}\right)
$$

精度$acc(f,D)$为

$$
   acc(f;D)=\frac{1}{m} \sum_{i=1}^{m}\mathbb{I} \left(f\left({x}_{i}\right)=y_{i}\right)
$$

$$
   acc(f;D)=1-E(f;D)
$$

> 更一般地，对于数据分布${D}$和概率密度函数$p(\cdot)$，错误率和精度与上述的情况类似。


## 查准率/准确率(Precision)、查全率/召回率(Recall)和$F_1$

对于二分类问题，我们的原始数据是被分为两类的（设他们分别是正、反类或0、1类），而在经过分类器分类之后，每一个数据样本都会被分类器认定为某一类（正（positive）或反（negative）），这也就是分类结果，最终判断其分类结果正确与否（true和false）。所以我们有一些符号设定：

> 1. 把原数据集中为正类，分类后仍为正类的样本集合记为TP（true positive）；
>
> 2. 把原数据集中为正类，但分类后为反类的样本集合记为FN（false negative）；
>
> 3. 把原数据集中为反类，但分类后为正类的样本集合记为FP（false positive）；
>
> 4. 把原数据集中为反类，分类后仍为反类的样本集合记为TN（true negative）；
>
>    （**T和F代表最终的分类结果是否正确；P和N代表分类的结果是正类或反类。**）

| 真实情况\预测结果 | 正例             | 反例             |
| ----------------- | ---------------- | ---------------- |
| 正例              | **T**P（真正例） | **F**N（假反例） |
| 反例              | **F**P（假正例） | **T**N（真反例） |

### 查准率与查全率

查准率P与查全率R分别定义为$P=\dfrac{TP}{TP+FP},R=\dfrac{TP}{TP+FN}$。

> 查准率和查全率是一对矛盾的度量。一般来说，查准率高时，查全率往往偏低；而查全率高时，查准率往往偏低。

### PR图

- 以P为纵轴、R为横轴绘出图像，得到了查准率—查全率曲线，简称“P-R曲线”。

- P-R图直观地显示出学习器在样本总体上的查全率、查准率。在进行比较时，若一个学习器的P-R曲线被另一个学习器的曲线完全“包住”，则可断言后者的性能优于前者。若出现**交点**则无法断言。

- 平衡点（**BEP**）是P=R时的取值，可以基于BEP进行比较。

### F1值和F1度量

- $F_1$是基于查准率和查全率的调和平均来定义的：$\dfrac{2}{F_1}=\dfrac{1}{P}+\dfrac{1}{R}\Rightarrow F_1=\dfrac{2\times P\times R}{P+R}$.

- $F_1$对查重率和查准率是同样重视的，$F_1$越大，我们认为性能越好。而在一些应用中，对查准率和查全率的重视程度有所不同。$F_1$度量的一般形式——$F_{\beta}$，能让我们表达出对查准率/查全率的不同偏好。

$$
   F_{\beta}=\frac{(1+{\beta}^2)PR}{\beta^2P+R}
$$

   其中，$\beta>0$度量了查全率对查准率的相对重要性。$\beta=1$，退化为$F_1$；$\beta>1$，查全率有较大影响；$\beta<1$，查准率有较大影响。

-  **“宏（微）查准率”、“宏（微）查全率”、“宏（微）$F_1$”**
   
   我们希望在n 个二分类混淆矩阵上综合考察查准率和查全率时，直接的做法是先在各混淆矩阵上分别计算出查准率和查全率，并计算它们的平均值。这样可以得出“宏查准率”、“宏查全率”和“宏$F_1$​”。

$$
   \begin{aligned}
      \text{macro-}P&=\frac{1}{n}\sum_{i=1}^{n}P_{i}\\
      \text{macro-}R&=\frac{1}{n}\sum_{i=1}^{n}R_{i}\\
      \text{macro-}F_1&=\frac{2\times\text{macro-}P\times\text{macro-}R}{\text{macro-}P+\text{macro-}R}
   \end{aligned}
$$

   还可先将各混淆矩阵的对应元素进行平均，得到TP、FP、TN、FN的平均值，分别记为$\overline{TP}$，$\overline{FP}$，$\overline{TN}$，$\overline{FN}$，再基于这些平均值计算出“微查准率”、“微查全率”和“微$F_1$”。

$$
   \begin{aligned}
      \text{micro-}P&=\frac{\overline{TP}}{\overline{TP}+\overline{FP}}\\
      \text{micro-}R&=\frac{\overline{TP}}{\overline{TP}+\overline{FN}}\\
      \text{micro-}F_1&=\frac{2\times\text{micro-}P\times\text{micro-}R}{\text{micro-}P+\text{micro-}R}
   \end{aligned}
$$

## ROC与AUC
- 在不同的应用任务中，我们可根据任务需求来采用不同的截断点，例如若我们更重视“查准率”，则可选择排序中靠前的位置进行截断；若更重视“查全率”，则可选择靠后的位置进行截断.因此，排序本身的质量好坏，体现了综合考虑学习器在不同任务下的“期望泛化性能”的好坏，或者说，“一般情况下”泛化性能的好坏。
- ROC曲线：Receiver Operating Characteristic curve，描述了当阈值变化时真正例率和假正例率的变化情况。横轴为假正例率（FPR），纵轴为真正例率（TPR）。
   
$$
   TPR=\frac{TP}{TP+FN}
$$
$$
   FPR=\frac{FP}{FP+TN}
$$

   > 1. ROC曲线越靠近左上角，分类器性能越好。
   > 2. ROC曲线下的面积AUC（Area Under ROC Curve）是对ROC曲线的一个数值化的描述，AUC越大，分类器性能越好。
   > 3. AUC的取值范围在0和1之间，AUC=0.5时，分类器性能等同于随机猜测。
- AUC：模型评估指标AUC(Area Under the Curve)，即ROC曲线下的面积。AUC值越大，说明模型的性能越好。AUC=1，是完美分类器，AUC=0.5是随机分类器。
   
## 代价敏感错误率与代价曲线
1. 在现实任务中，不同的错误分类代价可能是不同的，例如在医学诊断中，将病人诊断为健康人的代价要远远小于将健康人诊断为病人。因此，我们需要对不同的错误分类赋予不同的代价，这就是代价敏感错误率。
2. 代价曲线：描述了不同代价下的分类器性能。横轴为错误分类的代价比例，纵轴为分类器的性能度量。
3. 代价曲线的绘制步骤：
   1. 选择不同的阈值，得到不同的混淆矩阵；
   2. 根据混淆矩阵计算出不同代价下的错误率；
   3. 绘制代价曲线。
   4. 代价曲线的绘制过程中，我们可以选择不同的代价比例，得到不同的代价曲线，从而选择最优的代价比例。
